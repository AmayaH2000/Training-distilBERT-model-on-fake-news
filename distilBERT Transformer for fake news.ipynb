{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NnfoV0G6yr_Y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import  DataCollatorWithPadding\n",
    "from transformers import  TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YCWa2kDy1RQ",
    "outputId": "93a4c6e2-0e7d-4cce-de6b-aa653b05d57d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# Import a fake news dataset from HuggingFace repository:\n",
    "\n",
    "raw_datasets = load_dataset(\"GonzaloA/fake_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXUTFYjC4b_1",
    "outputId": "e6dd858c-be48-4966-f0ee-c56380e3e4f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 24353\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o-5RTAqFzINM"
   },
   "outputs": [],
   "source": [
    "# Load the distilBERT base uncased model and tokenize the data:\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, truncation=True,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wKB31uKEzPf0"
   },
   "outputs": [],
   "source": [
    "# GLUE's classification tasks, selecting sst2 (Standford Sentiment Treebank) for sentiment (positive or negative) classification task:\n",
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Z9mSt6TQzR8j"
   },
   "outputs": [],
   "source": [
    "task = \"sst2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ah00S32UzSD3"
   },
   "outputs": [],
   "source": [
    "# Functionalize the tokenizer process and ensure a maximum length on an input sentence that the model can handle is trundicated. All other samples will be padded to the maxiumum length.\n",
    "\n",
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples['title'], truncation=True,padding=True)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zbvLuWjyzSF7"
   },
   "outputs": [],
   "source": [
    "encoded_dataset = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUPbOCtQEHwU",
    "outputId": "9d86bd48-c3eb-4b22-a8b0-20e712d39b78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 24353\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-mgbmVXziF2",
    "outputId": "3df05002-8737-4108-f2de-a1887905851a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Finetune the model with training arguments:\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\"test-trainer\", num_train_epochs=3, max_steps=100)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "styFDhse4TIh",
    "outputId": "8bd8a963-b93a-4d09-f079-7609d1b67c02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-19ecdc70665e>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "# Benchmark the model with an accuracy metric using the predictions (logits) and labels:\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "580cLHEs6jeF"
   },
   "outputs": [],
   "source": [
    "# Compile, train and evaluate:\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "TqfqqaCNXoSp",
    "outputId": "e183088e-1786-4a18-a2e8-175d2dea2ea7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 05:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.35274051666259765, metrics={'train_runtime': 357.196, 'train_samples_per_second': 2.24, 'train_steps_per_second': 0.28, 'total_flos': 12685823224416.0, 'train_loss': 0.35274051666259765, 'epoch': 0.03})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "ZqWPZDTI6sHN",
    "outputId": "12fc41da-5fb7-4c5c-98e2-18395bc84c36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1015/1015 12:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.21315033733844757,\n",
       " 'eval_accuracy': 0.9223851176543058,\n",
       " 'eval_runtime': 776.4398,\n",
       " 'eval_samples_per_second': 10.454,\n",
       " 'eval_steps_per_second': 1.307,\n",
       " 'epoch': 0.03}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6icZIBSY_Opt"
   },
   "outputs": [],
   "source": [
    "# Performing some prediction to classify some samples with the trained model:\n",
    "\n",
    "raw_train_dataset = raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "q4aXcbG8L8CL",
    "outputId": "67c4b69a-afcd-4425-ef67-b95835164763"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' â€˜Mauryâ€™ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a fake news exerpt:\n",
    "raw_train_dataset[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUFduDKT-Txx",
    "outputId": "192f42f8-67ee-44bc-bd91-a5cc9d02727d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.98396933, 0.0160307 ]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The classification of the fake news exerpt:\n",
    "\n",
    "inputs = tokenizer(raw_train_dataset[0]['title'], return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "\n",
    "# Pass the logit outputs into a softmax function to get the probabilities of being fake and true:\n",
    "\n",
    "tf.nn.softmax(outputs[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2wilfZI6QSNN",
    "outputId": "daafc14c-e45e-403c-fc92-1148fcd9b8bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'U.N. says it believes Afghanistan air strike killed civilians'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a real news exerpt:\n",
    "raw_train_dataset[210]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dbhco0He-T0I",
    "outputId": "d5768ab7-6987-4538-ddf1-9672d41c09cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.02911408, 0.97088593]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The classification of the real news exerpt:\n",
    "\n",
    "inputs = tokenizer(raw_train_dataset[210]['title'], return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)\n",
    "outputs = model(**inputs, labels=labels)\n",
    "\n",
    "tf.nn.softmax(outputs[1].detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "X5NQvotK2p1r"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
